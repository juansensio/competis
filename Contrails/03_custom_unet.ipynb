{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 256 256\n",
      "256 128 128\n",
      "128 64 64\n",
      "64 64 64\n"
     ]
    }
   ],
   "source": [
    "from src.models.unet import Unet\n",
    "import torch \n",
    "\n",
    "unet = Unet('resnet18')\n",
    "unet;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 256, 256])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = unet(torch.randn(1, 9, 256, 256))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "traced = torch.jit.trace(unet, torch.rand(10, 9, 256, 256))\n",
    "traced;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced.save('unet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = torch.jit.load('unet.pt')\n",
    "loaded;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 256, 256])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded.eval()\n",
    "loaded.cuda()\n",
    "output = loaded(torch.randn(3, 9, 256, 256).cuda())\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\n\nforward(__torch__.src.models.decoder.___torch_mangle_1278.DecoderBlock self, Tensor x, Tensor skip) -> Tensor:\nExpected a value of type 'Tensor (inferred)' for argument 'skip' but instead found type 'Optional[Tensor]'.\nInferred 'skip' to be of type 'Tensor' because it was not annotated with an explicit type.\n:\n  File \"/home/juan/Desktop/competis/Contrails/src/models/decoder.py\", line 121\n        features = features[::-1]\n        for i, decoder_block in enumerate(self.blocks):\n            x = decoder_block(features[i], features[i+1] if i+1 < len(features) else None)\n                ~~~~~~~~~~~~~ <--- HERE\n        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=True)\n        x = self.out_conv(x)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[186], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m \n\u001b[0;32m----> 3\u001b[0m scripted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mscript(unet)\n\u001b[1;32m      4\u001b[0m scripted;\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/jit/_script.py:1284\u001b[0m, in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb, example_inputs)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n\u001b[1;32m   1283\u001b[0m     obj \u001b[39m=\u001b[39m call_prepare_scriptable_func(obj)\n\u001b[0;32m-> 1284\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49m_recursive\u001b[39m.\u001b[39;49mcreate_script_module(\n\u001b[1;32m   1285\u001b[0m         obj, torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49m_recursive\u001b[39m.\u001b[39;49minfer_methods_to_compile\n\u001b[1;32m   1286\u001b[0m     )\n\u001b[1;32m   1288\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mdict\u001b[39m):\n\u001b[1;32m   1289\u001b[0m     \u001b[39mreturn\u001b[39;00m create_script_dict(obj)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/jit/_recursive.py:480\u001b[0m, in \u001b[0;36mcreate_script_module\u001b[0;34m(nn_module, stubs_fn, share_types, is_tracing)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tracing:\n\u001b[1;32m    479\u001b[0m     AttributeTypeIsSupportedChecker()\u001b[39m.\u001b[39mcheck(nn_module)\n\u001b[0;32m--> 480\u001b[0m \u001b[39mreturn\u001b[39;00m create_script_module_impl(nn_module, concrete_type, stubs_fn)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/jit/_recursive.py:542\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    539\u001b[0m     script_module\u001b[39m.\u001b[39m_concrete_type \u001b[39m=\u001b[39m concrete_type\n\u001b[1;32m    541\u001b[0m \u001b[39m# Actually create the ScriptModule, initializing it with the function we just defined\u001b[39;00m\n\u001b[0;32m--> 542\u001b[0m script_module \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mRecursiveScriptModule\u001b[39m.\u001b[39;49m_construct(cpp_module, init_fn)\n\u001b[1;32m    544\u001b[0m \u001b[39m# Compile methods if necessary\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[39mif\u001b[39;00m concrete_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m concrete_type_store\u001b[39m.\u001b[39mmethods_compiled:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/jit/_script.py:614\u001b[0m, in \u001b[0;36mRecursiveScriptModule._construct\u001b[0;34m(cpp_module, init_fn)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \u001b[39mConstruct a RecursiveScriptModule that's ready for use. PyTorch\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[39mcode should use this to construct a RecursiveScriptModule instead\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[39m    init_fn:  Lambda that initializes the RecursiveScriptModule passed to it.\u001b[39;00m\n\u001b[1;32m    612\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    613\u001b[0m script_module \u001b[39m=\u001b[39m RecursiveScriptModule(cpp_module)\n\u001b[0;32m--> 614\u001b[0m init_fn(script_module)\n\u001b[1;32m    616\u001b[0m \u001b[39m# Finalize the ScriptModule: replace the nn.Module state with our\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[39m# custom implementations and flip the _initializing bit.\u001b[39;00m\n\u001b[1;32m    618\u001b[0m RecursiveScriptModule\u001b[39m.\u001b[39m_finalize_scriptmodule(script_module)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/jit/_recursive.py:520\u001b[0m, in \u001b[0;36mcreate_script_module_impl.<locals>.init_fn\u001b[0;34m(script_module)\u001b[0m\n\u001b[1;32m    517\u001b[0m     scripted \u001b[39m=\u001b[39m orig_value\n\u001b[1;32m    518\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     \u001b[39m# always reuse the provided stubs_fn to infer the methods to compile\u001b[39;00m\n\u001b[0;32m--> 520\u001b[0m     scripted \u001b[39m=\u001b[39m create_script_module_impl(orig_value, sub_concrete_type, stubs_fn)\n\u001b[1;32m    522\u001b[0m cpp_module\u001b[39m.\u001b[39msetattr(name, scripted)\n\u001b[1;32m    523\u001b[0m script_module\u001b[39m.\u001b[39m_modules[name] \u001b[39m=\u001b[39m scripted\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/jit/_recursive.py:546\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[39m# Compile methods if necessary\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[39mif\u001b[39;00m concrete_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m concrete_type_store\u001b[39m.\u001b[39mmethods_compiled:\n\u001b[0;32m--> 546\u001b[0m     create_methods_and_properties_from_stubs(concrete_type, method_stubs, property_stubs)\n\u001b[1;32m    547\u001b[0m     \u001b[39m# Create hooks after methods to ensure no name collisions between hooks and methods.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m     \u001b[39m# If done before, hooks can overshadow methods that aren't exported.\u001b[39;00m\n\u001b[1;32m    549\u001b[0m     create_hooks_from_stubs(concrete_type, hook_stubs, pre_hook_stubs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/jit/_recursive.py:397\u001b[0m, in \u001b[0;36mcreate_methods_and_properties_from_stubs\u001b[0;34m(concrete_type, method_stubs, property_stubs)\u001b[0m\n\u001b[1;32m    394\u001b[0m property_defs \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mdef_ \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m property_stubs]\n\u001b[1;32m    395\u001b[0m property_rcbs \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mresolution_callback \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m property_stubs]\n\u001b[0;32m--> 397\u001b[0m concrete_type\u001b[39m.\u001b[39;49m_create_methods_and_properties(property_defs, property_rcbs, method_defs, method_rcbs, method_defaults)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \n\nforward(__torch__.src.models.decoder.___torch_mangle_1278.DecoderBlock self, Tensor x, Tensor skip) -> Tensor:\nExpected a value of type 'Tensor (inferred)' for argument 'skip' but instead found type 'Optional[Tensor]'.\nInferred 'skip' to be of type 'Tensor' because it was not annotated with an explicit type.\n:\n  File \"/home/juan/Desktop/competis/Contrails/src/models/decoder.py\", line 121\n        features = features[::-1]\n        for i, decoder_block in enumerate(self.blocks):\n            x = decoder_block(features[i], features[i+1] if i+1 < len(features) else None)\n                ~~~~~~~~~~~~~ <--- HERE\n        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=True)\n        x = self.out_conv(x)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "scripted = torch.jit.script(unet)\n",
    "scripted;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted.save('unet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = torch.jit.load('unet.pt')\n",
    "loaded;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m loaded\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m      3\u001b[0m output \u001b[39m=\u001b[39m loaded(torch\u001b[39m.\u001b[39mrandn(\u001b[39m1\u001b[39m, \u001b[39m9\u001b[39m, \u001b[39m256\u001b[39m, \u001b[39m256\u001b[39m)\u001b[39m.\u001b[39mcuda())\n\u001b[0;32m----> 4\u001b[0m output\u001b[39m.\u001b[39;49mshape\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "loaded.eval()\n",
    "loaded.cuda()\n",
    "output = loaded(torch.randn(1, 9, 256, 256).cuda())\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 128, 128])\n",
      "torch.Size([1, 64, 64, 64])\n",
      "torch.Size([1, 128, 32, 32])\n",
      "torch.Size([1, 256, 16, 16])\n",
      "torch.Size([1, 512, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "for o in output:\n",
    "\tprint(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
